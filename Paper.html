<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI – hsicomp</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ebc57992554dae5230fa85c1bd5a55fa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI – hsicomp">
<meta property="og:description" content="HSI model compression evaluation">
<meta property="og:image" content="https://ninjalabo.github.io/hsicomp/images/Compression_techniques.png">
<meta property="og:site_name" content="hsicomp">
<meta property="og:image:height" content="1820">
<meta property="og:image:width" content="3179">
<meta name="twitter:title" content="Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI – hsicomp">
<meta name="twitter:description" content="HSI model compression evaluation">
<meta name="twitter:image" content="https://ninjalabo.github.io/hsicomp/images/Compression_techniques.png">
<meta name="twitter:image-height" content="1820">
<meta name="twitter:image-width" content="3179">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">hsicomp</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Paper.html">Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">hsicomp</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ARAD1K_HSCNN_Compression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Knowledge Distillation</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./arad1k_mst++_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral Reconstruction (CVPRW 2022)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./arad1k_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hyspecnet11k_quantization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hyspecnet11k_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HySpecNet-11k-Env_setup</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Paper.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Paper_Pruning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Poster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Poster_Pruning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">1. Introduction</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">2. Methodology</a></li>
  <li><a href="#experimental-setup" id="toc-experimental-setup" class="nav-link" data-scroll-target="#experimental-setup">3. Experimental Setup</a></li>
  <li><a href="#results-and-discussion" id="toc-results-and-discussion" class="nav-link" data-scroll-target="#results-and-discussion">4. Results and Discussion</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">5. Conclusion</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ninjalabo/hsicomp/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="Paper.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Leveraging Deep Neural Network Compression Techniques for Real-Time Hyperspectral Image Processing in Edge AI</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Authors: Dheeraj Kumar, Leila Mozaffari</p>
<section id="abstract" class="level3">
<h3 class="anchored" data-anchor-id="abstract">Abstract</h3>
<p>Hyperspectral imaging has become increasingly relevant in remote sensing applications due to its ability to capture detailed spectral information. The growth of hyperspectral datasets has necessitated efficient compression techniques to handle their massive storage requirements. This paper proposes a new approach that integrates the Spectral Signals Compressor Network (SSCNet), a state-of-the-art deep learning-based hyperspectral image compression model, with FasterAI pruning to improve compression efficiency. We used HySpecNet-11k, a large-scale hyperspectral benchmark dataset, to validate our approach. The results show significant improvements in compression rates while preserving high-quality image reconstruction, thus setting a new benchmark for learning-based hyperspectral image compression.</p>
<p>Model compression is a key technique used to reduce the memory footprint and computational demands of deep learning models, making them more suitable for deployment on resource-constrained devices. Model compression can be achieved through various techniques such as pruning, knowledge distillation, and quantization. Pruning, which is one such model compression technique, involves systematically removing unimportant weights or neurons from a network to reduce model size and computational complexity while maintaining acceptable levels of accuracy. In this paper, we implemented pruning from FasterAI to enhance SSCNet, making it more efficient without significantly compromising performance. We compare the original model and the pruned model to evaluate the benefits and impact of model compression.</p>
<p><img src="./images/Compression_techniques.png" class="img-fluid"></p>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">1. Introduction</h3>
<p>Recent advancements in hyperspectral imaging technology have led to the proliferation of hyperspectral data, significantly improving the identification and discrimination of materials in remote sensing applications. However, the resulting large volume of data necessitates efficient storage and transmission, driving research in hyperspectral image compression. Traditional approaches, which often combine transform coding and quantization techniques, face challenges when dealing with high-dimensional data. To address these limitations, learning-based methods leveraging convolutional autoencoders have emerged as promising alternatives for hyperspectral image compression [5].</p>
<p>In this paper, we present an improved hyperspectral image compression method by applying pruning using FasterAI on SSCNet [4], a convolutional autoencoder-based architecture. We leverage the HySpecNet-11k dataset [2], which provides a robust benchmark for training and evaluating learning-based hyperspectral image compression models.</p>
</section>
<section id="methodology" class="level3">
<h3 class="anchored" data-anchor-id="methodology">2. Methodology</h3>
<section id="hyspecnet-11k-dataset" class="level4">
<h4 class="anchored" data-anchor-id="hyspecnet-11k-dataset">2.1 HySpecNet-11k Dataset</h4>
<p>The HySpecNet-11k dataset was designed specifically for benchmarking learning-based hyperspectral image compression methods [5]. It consists of 11,483 non-overlapping image patches extracted from 250 EnMAP tiles, each patch containing 128×128 pixels with 224 spectral bands, and a ground sampling distance of 30m. These image patches provide a large-scale and diverse set of hyperspectral data acquired in spatially disjoint geographical regions, addressing the limitations of earlier datasets which often suffered from overfitting due to spatial similarity among samples.</p>
<p>For our experiments, we used the “easy split” setup for the dataset, where 70% of the image patches were used for training, 20% for validation, and 10% for testing. This ensured reproducibility and allowed for a comprehensive comparison with existing learning-based hyperspectral image compression techniques.</p>
</section>
<section id="spectral-signals-compressor-network-sscnet" class="level4">
<h4 class="anchored" data-anchor-id="spectral-signals-compressor-network-sscnet">2.2 Spectral Signals Compressor Network (SSCNet)</h4>
<p>SSCNet is a deep learning-based compression model that utilizes 2D convolutional layers with parametric ReLU activations for both spatial and spectral compression [4]. The encoder network employs 2D convolutions and three max pooling layers to achieve a fixed spatial compression factor of 64. The decoder mirrors the encoder, with upsampling achieved through transposed convolutional layers.</p>
<p>The compression ratio (CR) is set by the number of latent channels in the bottleneck layer, while the network’s ability to reconstruct the original image with minimal distortion is evaluated through Peak Signal-to-Noise Ratio (PSNR). SSCNet was chosen for this study due to its effectiveness in combining both spatial and spectral compression in hyperspectral datasets.</p>
</section>
<section id="fasterai-pruning" class="level4">
<h4 class="anchored" data-anchor-id="fasterai-pruning">2.3 FasterAI Pruning</h4>
<p>To enhance the performance of SSCNet, we implemented structured pruning from FasterAI, which systematically removes less important filters or neurons in the model’s layers. Pruning is particularly effective in reducing computational complexity and the memory footprint of deep learning models without significant degradation in accuracy.</p>
<p>In our work, we applied pruning during the fine-tuning phase, after training the SSCNet model. The pruning process involved identifying and removing low-magnitude weights or redundant neurons, followed by retraining the model to recover performance. This iterative process ensured that the pruned model maintained high reconstruction quality while achieving substantial reductions in model size and inference time.</p>
</section>
</section>
<section id="experimental-setup" class="level3">
<h3 class="anchored" data-anchor-id="experimental-setup">3. Experimental Setup</h3>
<p>The experimental setup used PyTorch as the deep learning framework. Gradient clipping and min-max normalization were applied to scale input data within a range suitable for learning-based models. The Adam optimizer was used with an initial learning rate of <span class="math inline">\(1e−4\)</span>, which was decreased as training progressed to achieve convergence.</p>
<p>Our experiments were conducted on a high-performance computing environment, featuring an NVIDIA L4 Tensor Core GPU with 24 GB memory. We tested the SSCNet model for 5 epochs, followed by pruning and fine-tuning for an additional 3 epochs.</p>
<p><img src="./images/Pipeline.png" class="img-fluid"></p>
</section>
<section id="results-and-discussion" class="level3">
<h3 class="anchored" data-anchor-id="results-and-discussion">4. Results and Discussion</h3>
<section id="compression-and-quality-analysis" class="level4">
<h4 class="anchored" data-anchor-id="compression-and-quality-analysis">4.1 Compression and Quality Analysis</h4>
<p>We evaluated the performance of our approach using the rate-distortion curve, measuring the trade-off between bits-per-pixel per channel (bpppc) and PSNR. Compared to the unpruned SSCNet model, the pruned SSCNet exhibited a significant reduction in model size and inference time with only a minor degradation in PSNR. At a compression rate of 2.53 bpppc, the pruned SSCNet achieved a PSNR of 42.98 dB, which is competitive when compared to traditional methods and non-pruned deep learning-based approaches.</p>
<p>Furthermore, pruning reduced the model size by approximately 45% and computational complexity by 50%, making the approach highly suitable for real-time remote sensing applications with constrained computational resources.</p>
<p><img src="./images/Results.png" class="img-fluid"></p>
</section>
<section id="comparative-analysis" class="level4">
<h4 class="anchored" data-anchor-id="comparative-analysis">4.2 Comparative Analysis</h4>
<p>To provide a comprehensive benchmark, we compared our pruned SSCNet model against other leading hyperspectral compression methods. Our proposed approach outperformed these methods in terms of compression efficiency and inference speed while achieving comparable PSNR values. The use of pruning positioned our method as a strong candidate for deployment in resource-constrained environments.</p>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">5. Conclusion</h3>
<p>This paper introduces a novel compression approach that combines the power of SSCNet for hyperspectral image compression with FasterAI’s pruning technique. The results show that this combined approach effectively reduces the memory footprint and computational requirements, making it suitable for real-time remote sensing applications while maintaining high reconstruction quality. Future work includes extending this approach to other hyperspectral datasets, exploring dynamic pruning strategies, and integrating additional compression techniques such as quantization for further performance improvements.</p>
</section>
<section id="acknowledgements" class="level3">
<h3 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h3>
<p>We also acknowledge the use of the HySpecNet-11k dataset and the Fasterai framework in conducting our experiments.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><p>[1] M. H. P. Fuchs and B. Demir, “Hyspecnet-11k: A large-scale hyperspectral dataset for benchmarking learning-based hyperspectral image compression methods,” in IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium, IEEE, 2023, pp.&nbsp;1779–1782.</p></li>
<li><p>[2] M. H. P. Fuchs and B. Demir, “HySpecNet-11k: A large-scale hyperspectral benchmark dataset.” Dryad, p.&nbsp;63608947808 bytes, Jun.&nbsp;26, 2023. doi: 10.5061/DRYAD.FTTDZ08ZH.</p></li>
<li><p>[3] R. La Grassa, C. Re, G. Cremonese, and I. Gallo, “Hyperspectral data compression using fully convolutional autoencoder,” Remote Sensing, vol.&nbsp;14, no. 10, p.&nbsp;2472, 2022.</p></li>
<li><p>[4] “FasterAI,” fasterai. Available: https://nathanhubens.github.io/fasterai/</p></li>
<li><p>[5] Fuchs, M. H. P., &amp; Demir, B. (2023). HySpecNet-11k: A Large-Scale Hyperspectral Dataset for Benchmarking Learning-Based Hyperspectral Image Compression Methods. arXiv preprint arXiv:2306.00385v2.</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ninjalabo\.github\.io\/hsicomp");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ninjalabo/hsicomp/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>