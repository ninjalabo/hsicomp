{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fasterbench.benchmark import evaluate_cpu_speed, get_model_size, get_num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1df8cb-a7a5-4b04-81c2-72766d3928f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "class dfus_block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(dfus_block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(dim, 128, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.conv_up1 = nn.Conv2d(128, 32, 3, 1, 1, bias=False)\n",
    "        self.conv_up2 = nn.Conv2d(32, 16, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.conv_down1 = nn.Conv2d(128, 32, 3, 1, 1, bias=False)\n",
    "        self.conv_down2 = nn.Conv2d(32, 16, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.conv_fution = nn.Conv2d(96, 32, 1, 1, 0, bias=False)\n",
    "\n",
    "        #### activation function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [b,c,h,w]\n",
    "        return out:[b,c,h,w]\n",
    "        \"\"\"\n",
    "        feat = self.relu(self.conv1(x))\n",
    "        feat_up1 = self.relu(self.conv_up1(feat))\n",
    "        feat_up2 = self.relu(self.conv_up2(feat_up1))\n",
    "        feat_down1 = self.relu(self.conv_down1(feat))\n",
    "        feat_down2 = self.relu(self.conv_down2(feat_down1))\n",
    "        feat_fution = torch.cat([feat_up1,feat_up2,feat_down1,feat_down2],dim=1)\n",
    "        feat_fution = self.relu(self.conv_fution(feat_fution))\n",
    "        out = torch.cat([x, feat_fution], dim=1)\n",
    "        return out\n",
    "\n",
    "class ddfn(nn.Module):\n",
    "    def __init__(self, dim, num_blocks=78):\n",
    "        super(ddfn, self).__init__()\n",
    "\n",
    "        self.conv_up1 = nn.Conv2d(dim, 32, 3, 1, 1, bias=False)\n",
    "        self.conv_up2 = nn.Conv2d(32, 32, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.conv_down1 = nn.Conv2d(dim, 32, 3, 1, 1, bias=False)\n",
    "        self.conv_down2 = nn.Conv2d(32, 32, 1, 1, 0, bias=False)\n",
    "\n",
    "        dfus_blocks = [dfus_block(dim=128+32*i) for i in range(num_blocks)]\n",
    "        self.dfus_blocks = nn.Sequential(*dfus_blocks)\n",
    "\n",
    "        #### activation function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [b,c,h,w]\n",
    "        return out:[b,c,h,w]\n",
    "        \"\"\"\n",
    "        feat_up1 = self.relu(self.conv_up1(x))\n",
    "        feat_up2 = self.relu(self.conv_up2(feat_up1))\n",
    "        feat_down1 = self.relu(self.conv_down1(x))\n",
    "        feat_down2 = self.relu(self.conv_down2(feat_down1))\n",
    "        feat_fution = torch.cat([feat_up1,feat_up2,feat_down1,feat_down2],dim=1)\n",
    "        out = self.dfus_blocks(feat_fution)\n",
    "        return out\n",
    "\n",
    "class HSCNN_Plus(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=31, num_blocks=30):\n",
    "        super(HSCNN_Plus, self).__init__()\n",
    "\n",
    "        self.ddfn = ddfn(dim=in_channels, num_blocks=num_blocks)\n",
    "        self.conv_out = nn.Conv2d(128+32*num_blocks, out_channels, 1, 1, 0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [b,c,h,w]\n",
    "        return out:[b,c,h,w]\n",
    "        \"\"\"\n",
    "        fea = self.ddfn(x)\n",
    "        out =  self.conv_out(fea)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd812e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# def get_dls(size, bs):\n",
    "#     path = URLs.IMAGENETTE_160\n",
    "#     source = untar_data(path)\n",
    "#     blocks=(ImageBlock, CategoryBlock)\n",
    "#     tfms = [RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)]\n",
    "#     batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n",
    "\n",
    "#     csv_file = 'noisy_imagenette.csv'\n",
    "#     inp = pd.read_csv(source/csv_file)\n",
    "#     dblock = DataBlock(blocks=blocks,\n",
    "#                splitter=ColSplitter(),\n",
    "#                get_x=ColReader('path', pref=source),\n",
    "#                get_y=ColReader(f'noisy_labels_0'),\n",
    "#                item_tfms=tfms,\n",
    "#                batch_tfms=batch_tfms)\n",
    "\n",
    "#     return dblock.dataloaders(inp, path=source, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# size, bs = 128, 32\n",
    "# dls = get_dls(size, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ebbdc-dda8-4ddb-8047-825c358d21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "model_path='/root/Ninjalabo/HSI/MST-plus-plus/MST-plus-plus/test_develop_code/model_zoo/hscnn_plus.pth'\n",
    "data_root= '/root/Ninjalabo/HSI/MST-plus-plus/MST-plus-plus/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378949f0-8cd0-46e3-9b1b-6d2da3a9f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# model_path = Path('/root/Ninjalabo/HSI/MST-plus-plus/MST-plus-plus/test_challenge_code/model_zoo/hscnn_plus.pth')\n",
    "\n",
    "# path = '/root/Ninjalabo/HSI/MST-plus-plus/MST-plus-plus/dataset/Train_RGB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25118f-7fef-48db-b6aa-962a3ab5388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Set your dataset path\n",
    "path = Path('/root/Ninjalabo/HSI/MST-plus-plus/MST-plus-plus/dataset/')\n",
    "val_path = path / 'Test_RGB'  # Adjust based on your folder structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c779c2-c66c-4eca-b5d1-341172f04f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# from fastai.vision.all import *\n",
    "\n",
    "# Define the path to your dataset\n",
    "path = Path('/root/Ninjalabo/HSI/MST-plus-plus/MST-plus-plus/dataset/')  # Set this to your validation data folder\n",
    "\n",
    "# DataBlock for image-to-image tasks\n",
    "data_block = DataBlock(\n",
    "    blocks=(ImageBlock, ImageBlock),  # Both input and output are images\n",
    "    get_items=get_image_files,  # Gets the image files\n",
    "    get_x=lambda f: PILImage.create(f),  # Use image as input\n",
    "    get_y=lambda f: PILImage.create(f),  # Use the same image as output\n",
    "    splitter=RandomSplitter(valid_pct=0.2),  # Split for training/validation (adjust as needed)\n",
    "    item_tfms=Resize(64),  # Resize transformation, adjust as per your requirement\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = data_block.dataloaders(path, bs=1)  # Adjust batch size based on memory limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6eae7c-9589-4843-8d8d-d57b9809d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| eval: false\n",
    "# dls = data_block.dataloaders(val_path, bs=5)  # Use the appropriate batch size\n",
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346971a3-145c-4832-aac7-64ee0ab5784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x) shape: torch.Size([5, 3, 64, 64])\n",
      "Target (y) shape: torch.Size([5, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Grab a batch from the training DataLoader\n",
    "x, y = dls.one_batch()\n",
    "\n",
    "# Check the shape of inputs and outputs\n",
    "print(\"Input (x) shape:\", x.shape)\n",
    "print(\"Target (y) shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79b5c5-8904-46ab-b0d7-d9dbaf3bb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | eval: false\n",
    "# model = HSCNN_Plus()\n",
    "# checkpoint = torch.load(model_path)\n",
    "# if 'state_dict' in checkpoint:\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# else:\n",
    "#     model.load_state_dict(checkpoint)\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb518c-989b-447b-aaad-6bb5d456b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)\n",
    "# print(torch.load(model_path).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958d8cd-0375-4f69-955d-f267f3714106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HSCNN_Plus(\n",
       "  (ddfn): ddfn(\n",
       "    (conv_up1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv_up2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv_down1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv_down2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (dfus_blocks): Sequential(\n",
       "      (0): dfus_block(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): dfus_block(\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): dfus_block(\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): dfus_block(\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): dfus_block(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): dfus_block(\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): dfus_block(\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): dfus_block(\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): dfus_block(\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): dfus_block(\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): dfus_block(\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): dfus_block(\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): dfus_block(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): dfus_block(\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): dfus_block(\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): dfus_block(\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): dfus_block(\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): dfus_block(\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): dfus_block(\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): dfus_block(\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): dfus_block(\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): dfus_block(\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): dfus_block(\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (23): dfus_block(\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (24): dfus_block(\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (25): dfus_block(\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (26): dfus_block(\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (27): dfus_block(\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (28): dfus_block(\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (29): dfus_block(\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_out): Conv2d(1088, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "model = HSCNN_Plus()  # Initialize your custom model\n",
    "# Load model checkpoint\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "if 'state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()  # Set to evaluation mode (good practice for inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcb93d-2b44-4ace-ac78-71f6fb1c1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "# Create the Learner with MSE Loss\n",
    "learn = Learner(dls, model, loss_func=MSELoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e673f9-42f7-4c77-be7a-d2264df25a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.047585</td>\n",
       "      <td>0.043253</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.045987</td>\n",
       "      <td>0.039191</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.043653</td>\n",
       "      <td>0.035421</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039822</td>\n",
       "      <td>0.032988</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from torch.nn import MSELoss\n",
    "# Train or fine-tune the model (optional)\n",
    "model = HSCNN_Plus(in_channels=3, out_channels=3, num_blocks=5)  # Reduce num_blocks significantly\n",
    "learn = Learner(dls, model.to('cpu'), loss_func=MSELoss())\n",
    "\n",
    "learn.fit_one_cycle(5, lr_max=1e-4)\n",
    "# learn.fit_one_cycle(4, 1e-4)\n",
    "# Run inference on validation set\n",
    "# preds, targs = learn.get_preds(dl=dls.valid)  # Get predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d0b4e-9fab-4341-b8ef-d527487f026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# from fastai.callback.all import GradientAccumulation\n",
    "\n",
    "# # Set gradient accumulation steps to effectively multiply your batch size by this factor\n",
    "# accumulation_steps = 8  # Adjust based on your needs and memory constraints\n",
    "\n",
    "# # Create the Learner with gradient accumulation and mixed precision\n",
    "# learn = Learner(dls, model, loss_func=MSELoss(), cbs=[GradientAccumulation(n_acc=accumulation_steps)]).to_fp16()\n",
    "# learn.fit_one_cycle(5, lr_max=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661104b5-b327-4acc-8d52-12478fc68227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# files = get_image_files(path)\n",
    "\n",
    "# def label_func(f): return f[0].isupper()\n",
    "\n",
    "# dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(128),bs=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc477de1-cb40-4f5e-8a8d-772671400e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f11bf-f072-425d-b662-e421dd22b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22ac17-2a16-44df-b8ab-4484b97fb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from torch.nn import MSELoss  # Use Mean Squared Error as loss function for image-to-image tasks\n",
    "\n",
    "# Define the Learner with MSE loss\n",
    "learn = Learner(dls, model, loss_func=MSELoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# learn = Learner(dls, model, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 2.08 MB (disk), 516640 parameters\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "num_parameters = get_num_parameters(learn.model)\n",
    "disk_size = get_model_size(learn.model)\n",
    "print(f\"Model Size: {disk_size / 1e6:.2f} MB (disk), {num_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "model = learn.model.eval().to('cpu')\n",
    "x,y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d310a-e937-4873-8199-20151be6de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Speed: 15.21ms\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(f'Inference Speed: {evaluate_cpu_speed(learn.model, x[0][None])[0]:.2f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5145e579-4af9-498e-9f1e-bc334636cff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([5, 3, 64, 64])\n",
      "Target Shape: torch.Size([5, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "x, y = dls.one_batch()\n",
    "print(\"Input Shape:\", x.shape)\n",
    "print(\"Target Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503c5d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3370f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f627246",
   "metadata": {},
   "source": [
    "## **Knowledge Distillation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149d8c9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<blockquote>\n",
    "<pre><b><i> KnowledgeDistillation(teacher.model, loss) </i></b></pre>\n",
    "<p style=\"font-size: 15px\"><i>\n",
    "You only need to give to the callback function your teacher learner. Behind the scenes, FasterAI will take care of making your model train using knowledge distillation.\n",
    "</i></p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83011770",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from fasterai.distill.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af77880-65c3-43d6-bc65-440d72c3a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8f286-a306-426f-8bdd-1f424f205ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718e802-2497-4207-8e14-a37d28fabaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6  # Total trainable parameters in millions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a60b06-8e56-4cd2-903c-5372ef2c79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# import torch\n",
    "\n",
    "# print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\")\n",
    "# print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a91897-0cf0-487d-a7d4-7c48a9b66cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862902d4-91ea-4bf3-91ed-3710fb1392bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# !kill -9 58089      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7417eb-8fad-4190-b90b-5768d91f6885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.042094</td>\n",
       "      <td>0.039655</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>0.037667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038269</td>\n",
       "      <td>0.029985</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>0.025685</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026424</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from torch.nn import MSELoss\n",
    "# Train or fine-tune the model (optional)\n",
    "model = HSCNN_Plus(in_channels=3, out_channels=3, num_blocks=5)  # Reduce num_blocks significantly\n",
    "teacher = Learner(dls, model.to('cpu'), loss_func=MSELoss())\n",
    "\n",
    "teacher.fit_one_cycle(10, lr_max=1e-4)\n",
    "# learn.fit_one_cycle(4, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e347b01-5b27-4f7a-a34b-62f3cf605664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>206.853897</td>\n",
       "      <td>4.708280</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>117.306244</td>\n",
       "      <td>4.507239</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>78.637085</td>\n",
       "      <td>3.295578</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>57.473248</td>\n",
       "      <td>2.667634</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44.227245</td>\n",
       "      <td>3.118005</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>35.264557</td>\n",
       "      <td>3.569392</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>28.856447</td>\n",
       "      <td>3.880894</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24.112537</td>\n",
       "      <td>4.008141</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20.488949</td>\n",
       "      <td>4.021497</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>17.672688</td>\n",
       "      <td>4.249494</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#| eval: false\n",
    "\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Step 1: Define the student model with Tiny U-Net structure\n",
    "# Use only the feature layers (up to the last convolution) of ResNet-18 as the encoder\n",
    "encoder = nn.Sequential(*list(resnet18(pretrained=True).children())[:-2])  # Remove the last fully connected layers\n",
    "student_model = DynamicUnet(encoder, n_out=3, img_size=(64, 64))  # Match output channels for your task\n",
    "\n",
    "# Step 2: Define the Learner for the student model\n",
    "# Set a suitable loss function for image-to-image tasks like MSELoss\n",
    "student = Learner(\n",
    "    dls, \n",
    "    student_model, \n",
    "    loss_func=MSELoss()#, \n",
    "    # metrics=[PSNR()]  # PSNR (Peak Signal-to-Noise Ratio) can be useful for image quality\n",
    ")\n",
    "\n",
    "# Step 3: Initialize the KnowledgeDistillationCallback\n",
    "# Assuming `teacher` is the pre-trained HSCNN_Plus model\n",
    "kd_cb = KnowledgeDistillationCallback(teacher.model, SoftTarget)\n",
    "\n",
    "# Step 4: Train the student model with knowledge distillation\n",
    "student.fit_one_cycle(10, 1e-4, cbs=kd_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4081c9-a48e-4fd5-a156-9facf469bd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 124.56 MB (disk), 31113108 parameters\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "num_parameters = get_num_parameters(student.model)\n",
    "disk_size = get_model_size(student.model)\n",
    "print(f\"Model Size: {disk_size / 1e6:.2f} MB (disk), {num_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f2e6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33622f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0ae5b",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fa530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from fasterai.quantize.quantize_callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938555c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.018870</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "teacher.fit_one_cycle(5, 1e-5, cbs=QuantizeCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390878b-4fab-4447-9fd8-77bf57a0dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Speed: 11.60ms\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(f'Inference Speed: {evaluate_cpu_speed(teacher.model, x[0][None])[0]:.2f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad298b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def count_parameters_quantized(model):\n",
    "    total_params = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.modules.conv.Conv2d) or \\\n",
    "           isinstance(module, torch.nn.Linear) or \\\n",
    "           isinstance(module, torch.ao.nn.quantized.modules.conv.Conv2d) or \\\n",
    "           isinstance(module, torch.ao.nn.quantized.modules.linear.Linear):\n",
    "            \n",
    "            total_params += module.weight().numel()\n",
    "            \n",
    "            if module.bias() is not None:\n",
    "                total_params += module.bias().numel()\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d556d-24db-40d9-a5ae-21f73306a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 0.59 MB (disk), 514,976 parameters\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "num_parameters = count_parameters_quantized(teacher.model)\n",
    "disk_size = get_model_size(teacher.model)\n",
    "print(f\"Model Size: {disk_size / 1e6:.2f} MB (disk), {num_parameters:,} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
