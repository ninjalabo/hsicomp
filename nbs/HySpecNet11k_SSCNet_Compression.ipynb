{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp SSCNetStaticQuantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSCNet Static Quantization\n",
    "\n",
    "> - In this we implement the quantization method from fasterai.\n",
    "> - The documentation are available here https://github.com/nathanhubens/fasterai.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-check installation of the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Pre-installation script for required libraries\\n\\nimport subprocess\\nimport sys\\n\\n# List of required libraries\\nrequired_libraries = [\\n    \"os\", \"sys\", \"torch\", \"time\", \"numpy\", \"pandas\", \"fastai\", \"pathlib\"\\n]\\n\\n# Function to check and install missing libraries\\ndef check_and_install_libraries(libraries):\\n    for lib in libraries:\\n        try:\\n            # Check if the library can be imported\\n            __import__(lib)\\n        except ImportError:\\n            # Special case for libraries with different pip names\\n            lib_pip = lib\\n            if lib == \"torch\":\\n                lib_pip = \"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\"\\n            elif lib == \"fastai\":\\n                lib_pip = \"fastai\"\\n\\n            print(f\"{lib} not found. Installing...\")\\n            try:\\n                subprocess.check_call(\\n                    [sys.executable, \"-m\", \"pip\", \"install\", lib_pip]\\n                )\\n                print(f\"{lib} installed successfully!\")\\n            except subprocess.CalledProcessError:\\n                print(f\"Failed to install {lib}. Please install it manually.\")\\n\\nif __name__ == \"__main__\":\\n    check_and_install_libraries(required_libraries)\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "\"\"\"\n",
    "# Pre-installation script for required libraries\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required libraries\n",
    "required_libraries = [\n",
    "    \"os\", \"sys\", \"torch\", \"time\", \"numpy\", \"pandas\", \"fastai\", \"pathlib\"\n",
    "]\n",
    "\n",
    "# Function to check and install missing libraries\n",
    "def check_and_install_libraries(libraries):\n",
    "    for lib in libraries:\n",
    "        try:\n",
    "            # Check if the library can be imported\n",
    "            __import__(lib)\n",
    "        except ImportError:\n",
    "            # Special case for libraries with different pip names\n",
    "            lib_pip = lib\n",
    "            if lib == \"torch\":\n",
    "                lib_pip = \"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\"\n",
    "            elif lib == \"fastai\":\n",
    "                lib_pip = \"fastai\"\n",
    "\n",
    "            print(f\"{lib} not found. Installing...\")\n",
    "            try:\n",
    "                subprocess.check_call(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", lib_pip]\n",
    "                )\n",
    "                print(f\"{lib} installed successfully!\")\n",
    "            except subprocess.CalledProcessError:\n",
    "                print(f\"Failed to install {lib}. Please install it manually.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_and_install_libraries(required_libraries)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Required imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from fastai.vision.all import DataLoader, DataLoaders\n",
    "from torch.utils.data import Dataset, DataLoader as TorchDataLoader\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Adjust paths for imports\n",
    "sys.path.append('/root/HSI_HypSpecNet11k/hsi-compression/')\n",
    "from quantizer import Quantizer\n",
    "from quantize_callback import QuantizeCallback\n",
    "sys.path.append('/root/HSI_HypSpecNet11k/hsi-compression/models/')\n",
    "from sscnet import SpectralSignalsCompressorNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have pre-trained weights, so we are using that in place of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Utility function to load pretrained weights\n",
    "def load_pretrained_weights(model, pretrained_weights_path):\n",
    "    print(f\"Loading pretrained weights from {pretrained_weights_path}...\")\n",
    "    checkpoint = torch.load(pretrained_weights_path)\n",
    "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    print(\"Pretrained weights loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| eval: false\n",
    "# Base directory for `.npy` files\n",
    "base_directory = '/root/HSI_HypSpecNet11k/hsi-compression/datasets/hyspecnet-11k/patches/'\n",
    "\n",
    "# Utility to load paths from a CSV file\n",
    "def load_paths(csv_file):\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    file_paths = [os.path.join(base_directory, x.strip()) for x in df[0]]\n",
    "    print(\"Paths loaded successfully.\")\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| eval: false\n",
    "# Dataset class for `.npy` files\n",
    "class NPYDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        sample = np.load(file_path)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        return sample, sample\n",
    "\n",
    "#| eval: false\n",
    "# Function to standardize samples\n",
    "def transform_sample(sample):\n",
    "    return (sample - np.mean(sample)) / np.std(sample)\n",
    "\n",
    "#| eval: false\n",
    "# Function to create DataLoaders\n",
    "def create_dataloaders(csv_file_path, batch_size=4, transform=None):\n",
    "    file_paths = load_paths(csv_file_path)\n",
    "    dataset = NPYDataset(file_paths, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return DataLoaders(dataloader, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| eval: false\n",
    "def quantization_pipeline_with_npy(model, pretrained_weights_path, csv_file_path, backend=\"x86\", batch_size=4, epochs=5, lr=1e-3):\n",
    "    def evaluate_model(model, test_dl):\n",
    "\n",
    "        print(\"Evaluating the model...\")\n",
    "        model.eval()\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in tqdm(test_dl, desc=\"Evaluating Batches\", leave=True):\n",
    "                xb = xb.to('cpu')\n",
    "                preds = model(xb)\n",
    "                loss = criterion(preds, xb)\n",
    "                total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(test_dl)\n",
    "        print(f\"Evaluation complete. Average Loss: {avg_loss:.6f}\")\n",
    "        return avg_loss\n",
    "\n",
    "    # Load pretrained weights\n",
    "    print(f\"Loading pretrained weights from {pretrained_weights_path}...\")\n",
    "    model.load_state_dict(torch.load(pretrained_weights_path)[\"state_dict\"], strict=False)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    print(f\"Creating DataLoaders using CSV file: {csv_file_path}\")\n",
    "    dls = create_dataloaders(csv_file_path, batch_size=batch_size, transform=transform_sample)\n",
    "\n",
    "    # Evaluate the non-quantized model\n",
    "    print(\"Evaluating the non-quantized model...\")\n",
    "    non_quantized_loss = evaluate_model(model, dls.valid)\n",
    "\n",
    "    # Set up FastAI Learner with QuantizeCallback\n",
    "    print(\"Setting up FastAI Learner with QuantizeCallback...\")\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        loss_func=torch.nn.MSELoss(),\n",
    "        cbs=QuantizeCallback(backend=backend),\n",
    "    )\n",
    "\n",
    "    # Train the model with quantization-aware training\n",
    "    print(\"Starting quantization-aware training...\")\n",
    "    learn.fit_one_cycle(epochs, lr)\n",
    "\n",
    "    # Quantized model after training\n",
    "    quantized_model = learn.model\n",
    "\n",
    "    # Evaluate the quantized model\n",
    "    print(\"Evaluating the quantized model...\")\n",
    "    quantized_loss = evaluate_model(quantized_model, dls.valid)\n",
    "\n",
    "    print(\"Quantization pipeline completed.\")\n",
    "    return quantized_model, non_quantized_loss, quantized_loss, dls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating KPIs for measuring the performace of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| eval: false\n",
    "# Performance measurement functions\n",
    "def measure_inference_time(model, dataloader, device=\"cuda\"):\n",
    "    \"\"\"Measure inference time for a model.\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in dataloader:\n",
    "            xb = xb.to(device)\n",
    "            _ = model(xb)\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| eval: false\n",
    "def measure_vram_usage(model, dataloader, device=\"cuda\"):\n",
    "    \"\"\"Simpler VRAM measurement.\"\"\"\n",
    "    try:\n",
    "        model.to(device)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in dataloader:\n",
    "                xb = xb.to(device)\n",
    "                _ = model(xb)\n",
    "        vram_peak = torch.cuda.max_memory_allocated(device) / 1e6  # Convert to MB\n",
    "    except RuntimeError:\n",
    "        print(\"VRAM measurement failed. Skipping.\")\n",
    "        vram_peak = -1  # Indicate failure\n",
    "    return vram_peak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the comparision table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| eval: false\n",
    "def generate_comparison_table(\n",
    "    model, quantized_model, non_quantized_loss, quantized_loss, test_dataloader, \n",
    "    pretrained_weights_path, quantized_weights_path, device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a comparison table for model performance metrics.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Measure model sizes\n",
    "    torch.save(model.state_dict(), pretrained_weights_path)\n",
    "    torch.save(quantized_model.state_dict(), quantized_weights_path)\n",
    "    model_size = os.path.getsize(pretrained_weights_path) / 1e6  # Convert to MB\n",
    "    quantized_size = os.path.getsize(quantized_weights_path) / 1e6\n",
    "\n",
    "    # Measure execution speed\n",
    "    print(\"Measuring execution speed...\")\n",
    "    non_quantized_speed = measure_inference_time(model, test_dataloader, device)\n",
    "    quantized_speed = measure_inference_time(quantized_model, test_dataloader, device)\n",
    "\n",
    "    # Measure VRAM usage (optional)\n",
    "    print(\"Measuring VRAM usage...\")\n",
    "    non_quantized_vram = measure_vram_usage(model, test_dataloader, device)\n",
    "    quantized_vram = measure_vram_usage(quantized_model, test_dataloader, device)\n",
    "\n",
    "    # Collect data\n",
    "    data.append([\"Model Size (MB)\", model_size, quantized_size])\n",
    "    data.append([\"Accuracy (Loss)\", non_quantized_loss, quantized_loss])\n",
    "    data.append([\"Execution Speed (s)\", non_quantized_speed, quantized_speed])\n",
    "    data.append([\"VRAM Usage (MB)\", non_quantized_vram, quantized_vram])\n",
    "\n",
    "    # Generate DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Metric\", \"Non-Quantized Model\", \"Quantized Model\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "from sscnet import SpectralSignalsCompressorNetwork  # Import SSCNet model\n",
    "from quantize_callback import QuantizeCallback  # Import QuantizeCallback\n",
    "from fastai.learner import Learner  # Import Learner from FastAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "pretrained_weights = \"/root/HSI_HypSpecNet11k/hsi-compression/results/weights/sscnet_2point5bpppc.pth.tar\"\n",
    "csv_file_path = \"/root/HSI_HypSpecNet11k/hsi-compression/datasets/hyspecnet-11k/splits/easy/test.csv\"\n",
    "quantized_weights_path = \"/root/HSI_HypSpecNet11k/hsi-compression/compressed_model/quantized_sscnet.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Initialize the model\n",
    "model = SpectralSignalsCompressorNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the quantization pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization Pipeline Progress:   0%|                                                                          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_132936/1989001652.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(pretrained_weights_path)[\"state_dict\"], strict=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from /root/HSI_HypSpecNet11k/hsi-compression/results/weights/sscnet_2point5bpppc.pth.tar...\n",
      "Model loaded successfully.\n",
      "Creating DataLoaders using CSV file: /root/HSI_HypSpecNet11k/hsi-compression/datasets/hyspecnet-11k/splits/easy/test.csv\n",
      "Paths loaded successfully.\n",
      "Evaluating the non-quantized model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Batches:   0%|                                                                                       | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating Batches:   2%|█▎                                                                             | 1/61 [00:00<00:58,  1.03it/s]\u001b[A\n",
      "Evaluating Batches:   3%|██▌                                                                            | 2/61 [00:01<00:56,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:   5%|███▉                                                                           | 3/61 [00:02<00:55,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:   7%|█████▏                                                                         | 4/61 [00:03<00:53,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:   8%|██████▍                                                                        | 5/61 [00:04<00:52,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  10%|███████▊                                                                       | 6/61 [00:05<00:51,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  11%|█████████                                                                      | 7/61 [00:06<00:50,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  13%|██████████▎                                                                    | 8/61 [00:07<00:49,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  15%|███████████▋                                                                   | 9/61 [00:08<00:49,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  16%|████████████▊                                                                 | 10/61 [00:09<00:48,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  18%|██████████████                                                                | 11/61 [00:10<00:47,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  20%|███████████████▎                                                              | 12/61 [00:11<00:46,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  21%|████████████████▌                                                             | 13/61 [00:12<00:45,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  23%|█████████████████▉                                                            | 14/61 [00:13<00:44,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  25%|███████████████████▏                                                          | 15/61 [00:14<00:43,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  26%|████████████████████▍                                                         | 16/61 [00:15<00:42,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  28%|█████████████████████▋                                                        | 17/61 [00:16<00:41,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  30%|███████████████████████                                                       | 18/61 [00:16<00:40,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  31%|████████████████████████▎                                                     | 19/61 [00:17<00:39,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  33%|█████████████████████████▌                                                    | 20/61 [00:18<00:38,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  34%|██████████████████████████▊                                                   | 21/61 [00:19<00:37,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  36%|████████████████████████████▏                                                 | 22/61 [00:20<00:36,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  38%|█████████████████████████████▍                                                | 23/61 [00:21<00:35,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  39%|██████████████████████████████▋                                               | 24/61 [00:22<00:34,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  41%|███████████████████████████████▉                                              | 25/61 [00:23<00:33,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  43%|█████████████████████████████████▏                                            | 26/61 [00:24<00:32,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  44%|██████████████████████████████████▌                                           | 27/61 [00:25<00:32,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  46%|███████████████████████████████████▊                                          | 28/61 [00:26<00:31,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  48%|█████████████████████████████████████                                         | 29/61 [00:27<00:30,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  49%|██████████████████████████████████████▎                                       | 30/61 [00:28<00:29,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  51%|███████████████████████████████████████▋                                      | 31/61 [00:29<00:28,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  52%|████████████████████████████████████████▉                                     | 32/61 [00:30<00:27,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  54%|██████████████████████████████████████████▏                                   | 33/61 [00:31<00:26,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  56%|███████████████████████████████████████████▍                                  | 34/61 [00:32<00:25,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  57%|████████████████████████████████████████████▊                                 | 35/61 [00:33<00:24,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  59%|██████████████████████████████████████████████                                | 36/61 [00:33<00:23,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  61%|███████████████████████████████████████████████▎                              | 37/61 [00:34<00:22,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  62%|████████████████████████████████████████████████▌                             | 38/61 [00:35<00:21,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  64%|█████████████████████████████████████████████████▊                            | 39/61 [00:36<00:20,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  66%|███████████████████████████████████████████████████▏                          | 40/61 [00:37<00:19,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  67%|████████████████████████████████████████████████████▍                         | 41/61 [00:38<00:18,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:  69%|█████████████████████████████████████████████████████▋                        | 42/61 [00:39<00:18,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:  70%|██████████████████████████████████████████████████████▉                       | 43/61 [00:40<00:17,  1.03it/s]\u001b[A\n",
      "Evaluating Batches:  72%|████████████████████████████████████████████████████████▎                     | 44/61 [00:42<00:18,  1.11s/it]\u001b[A\n",
      "Evaluating Batches:  74%|█████████████████████████████████████████████████████████▌                    | 45/61 [00:43<00:17,  1.07s/it]\u001b[A\n",
      "Evaluating Batches:  75%|██████████████████████████████████████████████████████████▊                   | 46/61 [00:44<00:15,  1.03s/it]\u001b[A\n",
      "Evaluating Batches:  77%|████████████████████████████████████████████████████████████                  | 47/61 [00:44<00:14,  1.01s/it]\u001b[A\n",
      "Evaluating Batches:  79%|█████████████████████████████████████████████████████████████▍                | 48/61 [00:45<00:12,  1.01it/s]\u001b[A\n",
      "Evaluating Batches:  80%|██████████████████████████████████████████████████████████████▋               | 49/61 [00:46<00:11,  1.02it/s]\u001b[A\n",
      "Evaluating Batches:  82%|███████████████████████████████████████████████████████████████▉              | 50/61 [00:47<00:10,  1.04it/s]\u001b[A\n",
      "Evaluating Batches:  84%|█████████████████████████████████████████████████████████████████▏            | 51/61 [00:48<00:09,  1.04it/s]\u001b[A\n",
      "Evaluating Batches:  85%|██████████████████████████████████████████████████████████████████▍           | 52/61 [00:49<00:08,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:  87%|███████████████████████████████████████████████████████████████████▊          | 53/61 [00:50<00:07,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:  89%|█████████████████████████████████████████████████████████████████████         | 54/61 [00:51<00:06,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:  90%|██████████████████████████████████████████████████████████████████████▎       | 55/61 [00:52<00:05,  1.05it/s]\u001b[A\n",
      "Evaluating Batches:  92%|███████████████████████████████████████████████████████████████████████▌      | 56/61 [00:53<00:04,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  93%|████████████████████████████████████████████████████████████████████████▉     | 57/61 [00:54<00:03,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  95%|██████████████████████████████████████████████████████████████████████████▏   | 58/61 [00:55<00:02,  1.06it/s]\u001b[A\n",
      "Evaluating Batches:  97%|███████████████████████████████████████████████████████████████████████████▍  | 59/61 [00:56<00:01,  1.04it/s]\u001b[A\n",
      "Evaluating Batches:  98%|████████████████████████████████████████████████████████████████████████████▋ | 60/61 [00:57<00:00,  1.05it/s]\u001b[A\n",
      "Evaluating Batches: 100%|██████████████████████████████████████████████████████████████████████████████| 61/61 [00:58<00:00,  1.05it/s]\u001b[A\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Average Loss: 0.906979\n",
      "Setting up FastAI Learner with QuantizeCallback...\n",
      "Starting quantization-aware training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.698915</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.789574</td>\n",
       "      <td>0.803140</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.793944</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.785297</td>\n",
       "      <td>0.781653</td>\n",
       "      <td>04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.778963</td>\n",
       "      <td>0.785001</td>\n",
       "      <td>04:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the quantized model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Batches:   0%|                                                                                       | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating Batches:   2%|█▎                                                                             | 1/61 [00:00<00:33,  1.77it/s]\u001b[A\n",
      "Evaluating Batches:   3%|██▌                                                                            | 2/61 [00:01<00:31,  1.87it/s]\u001b[A\n",
      "Evaluating Batches:   5%|███▉                                                                           | 3/61 [00:01<00:30,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:   7%|█████▏                                                                         | 4/61 [00:02<00:30,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:   8%|██████▍                                                                        | 5/61 [00:02<00:29,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  10%|███████▊                                                                       | 6/61 [00:03<00:28,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  11%|█████████                                                                      | 7/61 [00:03<00:28,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  13%|██████████▎                                                                    | 8/61 [00:04<00:27,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  15%|███████████▋                                                                   | 9/61 [00:04<00:27,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  16%|████████████▊                                                                 | 10/61 [00:05<00:26,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  18%|██████████████                                                                | 11/61 [00:05<00:26,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  20%|███████████████▎                                                              | 12/61 [00:06<00:25,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  21%|████████████████▌                                                             | 13/61 [00:06<00:25,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  23%|█████████████████▉                                                            | 14/61 [00:07<00:24,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  25%|███████████████████▏                                                          | 15/61 [00:07<00:23,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  26%|████████████████████▍                                                         | 16/61 [00:08<00:23,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  28%|█████████████████████▋                                                        | 17/61 [00:08<00:22,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  30%|███████████████████████                                                       | 18/61 [00:09<00:22,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  31%|████████████████████████▎                                                     | 19/61 [00:09<00:21,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  33%|█████████████████████████▌                                                    | 20/61 [00:10<00:21,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  34%|██████████████████████████▊                                                   | 21/61 [00:11<00:20,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  36%|████████████████████████████▏                                                 | 22/61 [00:11<00:20,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  38%|█████████████████████████████▍                                                | 23/61 [00:12<00:19,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  39%|██████████████████████████████▋                                               | 24/61 [00:12<00:19,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  41%|███████████████████████████████▉                                              | 25/61 [00:13<00:18,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  43%|█████████████████████████████████▏                                            | 26/61 [00:13<00:18,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  44%|██████████████████████████████████▌                                           | 27/61 [00:14<00:17,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:  46%|███████████████████████████████████▊                                          | 28/61 [00:14<00:17,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  48%|█████████████████████████████████████                                         | 29/61 [00:15<00:16,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  49%|██████████████████████████████████████▎                                       | 30/61 [00:15<00:16,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  51%|███████████████████████████████████████▋                                      | 31/61 [00:16<00:15,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  52%|████████████████████████████████████████▉                                     | 32/61 [00:16<00:15,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  54%|██████████████████████████████████████████▏                                   | 33/61 [00:17<00:14,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:  56%|███████████████████████████████████████████▍                                  | 34/61 [00:17<00:14,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:  57%|████████████████████████████████████████████▊                                 | 35/61 [00:18<00:13,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  59%|██████████████████████████████████████████████                                | 36/61 [00:18<00:13,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  61%|███████████████████████████████████████████████▎                              | 37/61 [00:19<00:12,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  62%|████████████████████████████████████████████████▌                             | 38/61 [00:19<00:12,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  64%|█████████████████████████████████████████████████▊                            | 39/61 [00:20<00:11,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  66%|███████████████████████████████████████████████████▏                          | 40/61 [00:20<00:10,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  67%|████████████████████████████████████████████████████▍                         | 41/61 [00:21<00:10,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  69%|█████████████████████████████████████████████████████▋                        | 42/61 [00:21<00:09,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  70%|██████████████████████████████████████████████████████▉                       | 43/61 [00:22<00:09,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  72%|████████████████████████████████████████████████████████▎                     | 44/61 [00:23<00:08,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  74%|█████████████████████████████████████████████████████████▌                    | 45/61 [00:23<00:08,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  75%|██████████████████████████████████████████████████████████▊                   | 46/61 [00:24<00:07,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:  77%|████████████████████████████████████████████████████████████                  | 47/61 [00:24<00:07,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:  79%|█████████████████████████████████████████████████████████████▍                | 48/61 [00:25<00:06,  1.90it/s]\u001b[A\n",
      "Evaluating Batches:  80%|██████████████████████████████████████████████████████████████▋               | 49/61 [00:25<00:06,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  82%|███████████████████████████████████████████████████████████████▉              | 50/61 [00:26<00:05,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  84%|█████████████████████████████████████████████████████████████████▏            | 51/61 [00:26<00:05,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  85%|██████████████████████████████████████████████████████████████████▍           | 52/61 [00:27<00:04,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  87%|███████████████████████████████████████████████████████████████████▊          | 53/61 [00:27<00:04,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  89%|█████████████████████████████████████████████████████████████████████         | 54/61 [00:28<00:03,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  90%|██████████████████████████████████████████████████████████████████████▎       | 55/61 [00:28<00:03,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  92%|███████████████████████████████████████████████████████████████████████▌      | 56/61 [00:29<00:02,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  93%|████████████████████████████████████████████████████████████████████████▉     | 57/61 [00:29<00:02,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  95%|██████████████████████████████████████████████████████████████████████████▏   | 58/61 [00:30<00:01,  1.91it/s]\u001b[A\n",
      "Evaluating Batches:  97%|███████████████████████████████████████████████████████████████████████████▍  | 59/61 [00:30<00:01,  1.92it/s]\u001b[A\n",
      "Evaluating Batches:  98%|████████████████████████████████████████████████████████████████████████████▋ | 60/61 [00:31<00:00,  1.92it/s]\u001b[A\n",
      "Evaluating Batches: 100%|██████████████████████████████████████████████████████████████████████████████| 61/61 [00:31<00:00,  1.91it/s]\u001b[A\n",
      "Quantization Pipeline Progress:  70%|█████████████████████████████████████████████▌                   | 70/100 [23:19<09:59, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Average Loss: 0.800412\n",
      "Quantization pipeline completed.\n",
      "\n",
      "Pipeline completed. Metrics:\n",
      "Error during quantization pipeline: 'float' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "# Step 1: Initialize and start the quantization pipeline\n",
    "print(\"Running the quantization pipeline...\")\n",
    "\n",
    "# Create a progress bar\n",
    "with tqdm(total=100, desc=\"Quantization Pipeline Progress\", leave=True) as pbar:\n",
    "    try:\n",
    "        # Run the quantization pipeline\n",
    "        quantized_model, non_quantized_metrics, quantized_metrics, dls = quantization_pipeline_with_npy(\n",
    "            model=model,\n",
    "            pretrained_weights_path=pretrained_weights,\n",
    "            csv_file_path=csv_file_path,\n",
    "            backend=\"x86\",\n",
    "            batch_size=4,\n",
    "            epochs=5,\n",
    "            lr=1e-3,\n",
    "        )\n",
    "\n",
    "        # Update progress bar to reflect pipeline progress (e.g., 70% complete after pipeline)\n",
    "        pbar.update(70)\n",
    "\n",
    "        # Step 2: Print the metrics\n",
    "        # Clear GPU memory to prevent memory leaks\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"\\nPipeline completed. Metrics:\")\n",
    "        print(f\"Non-Quantized Model Metrics: Loss = {non_quantized_metrics['loss']:.6f}\")\n",
    "        print(f\"Quantized Model Metrics: Loss = {quantized_metrics['loss']:.6f}\")\n",
    "\n",
    "        # Update progress bar to completion\n",
    "        pbar.update(30)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during quantization pipeline: {e}\")\n",
    "        # Close progress bar to avoid hanging display\n",
    "        pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 55.141518 MB, Quantized Size: 13.844594 MB\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "# Test model size measurement\n",
    "model_size = os.path.getsize(pretrained_weights) / 1e6\n",
    "quantized_size = os.path.getsize(quantized_weights_path) / 1e6\n",
    "print(f\"Model Size: {model_size} MB, Quantized Size: {quantized_size} MB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader size: 61\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "try:\n",
    "    print(f\"Validation DataLoader size: {len(dls.valid)}\")\n",
    "except NameError:\n",
    "    print(\"DataLoaders not found. Recreating...\")\n",
    "    dls = create_dataloaders(csv_file_path, batch_size=4, transform=transform_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 3.04s\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "# Test execution speed\n",
    "speed = measure_inference_time(model, dls.valid)\n",
    "print(f\"Inference Time: {speed:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM Usage: 410.94 MB\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "# Test VRAM usage\n",
    "vram_usage = measure_vram_usage(model, dls.valid)\n",
    "print(f\"VRAM Usage: {vram_usage:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
